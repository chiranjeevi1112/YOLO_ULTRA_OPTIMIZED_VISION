# Ultra-Optimized Real-Time Vision Streaming System

This repository implements a **high-performance real-time vision inference system** with a hybrid architecture:

- **TCP Data Plane** â†’ streams raw frames using msgpack  
- **FastAPI Control Plane** â†’ provides health, metrics, and WebSocket events  
- **Async YOLO Inference Pipeline** â†’ CPU/GPU, multi-worker  
- **Unified Client Tools** â†’ webcam/video/image-folder/synthetic  
- **Stress Testing System** â†’ simulate multiple cameras  
- **Live Visualizer** â†’ real-time bounding box overlay  

This project demonstrates scalable, low-latency, multi-stream deep-learning inference.

---

# âœ¨ Features

### âœ” Asynchronous TCP Frame Server  
- Processes frames from any number of clients  
- Msgpack + length-prefix protocol  
- Frame queue + backpressure handling  
- Per-stream processing isolation  

### âœ” YOLOv8 Inference (CPU/GPU)  
- Loads model once  
- Warm-up pass for faster first inference  
- Supports custom model paths  
- Fallback â€œdummy detectionâ€ if no model installed  

### âœ” FastAPI Control Plane  
Endpoints:
- `/health` â†’ server alive  
- `/stats` â†’ processed frames, dropped frames, FPS, latency, CPU/RAM, queue size  
- `/ws` â†’ WebSocket live detection broadcast  

### âœ” Unified Streaming Client  
Supports:
- **Webcam**  
- **Video file**  
- **Image folder playback**  
- **Synthetic frames (random noise)**  

Saves server results to:

### âœ” Stress Test Framework  
Simulates many parallel clients to measure:
- Throughput  
- Frame drops  
- Latency stability  
- Worker saturation  

### âœ” Live Visualizer  
- Webcam â†’ Server â†’ Detections â†’ OpenCV window  
- Draws bounding boxes and labels  
- Useful for demos and validation  

---

# ğŸ“¦ Installation

Create virtual environment (recommended):

```bash
python -m venv .venv
# Windows:
.venv\Scripts\activate
# Linux/Mac:
source .venv/bin/activate

Install dependencies:

pip install -r requirements.txt
